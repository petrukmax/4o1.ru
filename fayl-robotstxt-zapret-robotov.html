<!DOCTYPE html><html lang="ru"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><title>файл ROBOTS.TXT запрет роботов - Blog</title><meta name="description" content="Файл robots.txt сообщает поисковым роботам, разрешено или нет сканирование и индексация различных частей сайта. Этот текстовый файл должен обязательно называться именно так — robots.txt (все с маленькой буквы), — и лежать в корневой директории сайта. Всегда полезно проверить, есть ли доступ к файлу роботс со стороны поисковых систем. Для этого достаточно в строке браузера ввести его URL-адрес, например, так: http://com-seo.ru/robots.txt (для этого сайта)."><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://4o1.ru/fayl-robotstxt-zapret-robotov.html"><link rel="alternate" type="application/atom+xml" href="https://4o1.ru/feed.xml"><link rel="alternate" type="application/json" href="https://4o1.ru/feed.json"><meta property="og:title" content="файл ROBOTS.TXT запрет роботов"><meta property="og:site_name" content="Blog"><meta property="og:description" content="Файл robots.txt сообщает поисковым роботам, разрешено или нет сканирование и индексация различных частей сайта. Этот текстовый файл должен обязательно называться именно так — robots.txt (все с маленькой буквы), — и лежать в корневой директории сайта. Всегда полезно проверить, есть ли доступ к файлу роботс со стороны поисковых систем. Для этого достаточно в строке браузера ввести его URL-адрес, например, так: http://com-seo.ru/robots.txt (для этого сайта)."><meta property="og:url" content="https://4o1.ru/fayl-robotstxt-zapret-robotov.html"><meta property="og:type" content="article"><link rel="stylesheet" href="https://4o1.ru/assets/css/fontawesome-all.min.css?v=85514f933f9e0b82460af63f1a403fa5"><link rel="stylesheet" href="https://4o1.ru/assets/css/style.css?v=9274fb62a8095432057114afc1a7f7fc"><noscript><link rel="stylesheet" href="https://4o1.ru/assets/css/noscript.css?v=efa867a99f5064d6729e4dc2008ad50b"></noscript><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://4o1.ru/fayl-robotstxt-zapret-robotov.html"},"headline":"файл ROBOTS.TXT запрет роботов","datePublished":"2013-02-12T14:03+04:00","dateModified":"2024-08-19T17:47+03:00","description":"Файл robots.txt сообщает поисковым роботам, разрешено или нет сканирование и индексация различных частей сайта. Этот текстовый файл должен обязательно называться именно так — robots.txt (все с маленькой буквы), — и лежать в корневой директории сайта. Всегда полезно проверить, есть ли доступ к файлу роботс со стороны поисковых систем. Для этого достаточно в строке браузера ввести его URL-адрес, например, так: http://com-seo.ru/robots.txt (для этого сайта).","author":{"@type":"Person","name":"GUIDETO","url":"https://4o1.ru/authors/admin/"},"publisher":{"@type":"Organization","name":"GUIDETO"}}</script><style>#wrapper > .bg {
               background-image: url(https://4o1.ru/assets/images/overlay.png), linear-gradient(0deg, rgba(0, 0, 0, 0.1), rgba(0, 0, 0, 0.1)), url();
           }</style><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="is-preload post-template"><div id="wrapper"><header id="header"><a class="logo" href="https://4o1.ru/">Blog</a></header><nav id="nav"><ul class="links"><li><a href="https://4o1.ru/tags/kouching/" target="_self">Коучинг</a></li><li><a href="https://4o1.ru/tags/psixologiya/" target="_self">Психология</a></li><li><a href="https://4o1.ru/tags/knigi/" target="_self">Книги</a></li><li><a href="https://4o1.ru/tags/video/" target="_self">Видео</a></li><li><a href="https://4o1.ru/tags/biz/" target="_self">Бизнес</a></li><li><a href="https://4o1.ru/tags/bez-rubriki/" target="_self">Без рубрики</a></li><li><a href="https://4o1.ru/tags/audiobook/" target="_self">Аудиокниги</a></li><li><a href="https://4o1.ru/tags/anglijskij/" target="_self">Английский</a></li><li class="has-submenu"><a href="https://4o1.ru/tags/it/" target="_self" aria-haspopup="true">IT</a><ul class="nav__submenu level-2" aria-hidden="true"><li><a href="https://4o1.ru/tags/wordpress/" target="_self">WordPress</a></li><li><a href="https://4o1.ru/tags/seo/" target="_self">SEO</a></li><li class="has-submenu"><a href="https://4o1.ru/tags/yazyki/" target="_self" aria-haspopup="true">Языки</a><ul class="nav__submenu level-3" aria-hidden="true"><li><a href="https://4o1.ru/tags/html/" target="_self">HTML</a></li><li><a href="https://4o1.ru/tags/php/" target="_self">PHP</a></li></ul></li><li><a href="https://4o1.ru/tags/hard/" target="_self">Железо</a></li><li><a href="https://4o1.ru/tags/android/" target="_self">Android</a></li><li class="has-submenu"><a href="https://4o1.ru/tags/windows/" target="_self" aria-haspopup="true">Windows</a><ul class="nav__submenu level-3" aria-hidden="true"><li><a href="https://4o1.ru/tags/iis/" target="_self">IIS</a></li></ul></li><li class="has-submenu"><a href="https://4o1.ru/tags/unix/" target="_self" aria-haspopup="true">Unix</a><ul class="nav__submenu level-3" aria-hidden="true"><li><a href="https://4o1.ru/tags/apache/" target="_self">Apache</a></li><li><a href="https://4o1.ru/tags/asterisk/" target="_self">Asterisk</a></li></ul></li></ul></li></ul></nav><main id="main"><article class="post"><header class="major"><time datetime="2013-02-12T14:03" class="date">февраль 12, 2013</time><h1>файл ROBOTS.TXT запрет роботов</h1><p class="post__inner"></p></header><div class="post__inner post__entry"><p><strong>Файл robots.txt</strong> сообщает поисковым роботам, разрешено или нет сканирование и индексация различных частей сайта. Этот текстовый файл должен обязательно называться именно так — <em>robots.txt</em> (все с маленькой буквы), — и лежать в корневой директории сайта. Всегда полезно проверить, есть ли доступ к файлу роботс со стороны поисковых систем. Для этого достаточно в строке браузера ввести его URL-адрес, например, так: http://com-seo.ru/robots.txt (для этого сайта).</p><h2>Как пользоваться файлом ROBOTS.TXT для запрета робота?</h2><p>Все основные поисковые роботы понимают записи в файле robots.txt одинаково. Разберем для примера короткий пример, как пользоваться файлом роботс, который ставит запрет для роботов на доступ к файлам сайта:</p><p><em>User-agent: *</em></p><p>Dissallow: /images/</p><p>Disallow: /search</p><p>Этот пример запрещает всем поисковым роботам (указано символом *) доступ к директории сайта «images», а также по всем файлам, путь к которым начинается со слова «search». Как правило, <strong>запрет для поискового робота</strong> используется в тех случаях, когда веб-мастер считает, что некоторым страницам сайта не следует появляться в результатах выдачи поисковых систем, поскольку они бесполезны для посетителей.</p><p>Чтобы не ошибиться и не поставить поисковым роботам запреты на полезные директории и файлы, Гугл рекомендует использовать инструмент по проверке файла роботс из своей панели управления для веб-мастеров (Google Webmasters Tools, или сокращенно WMT). Если на сайте используются поддомены, и есть необходимость запретить сканирование отдельных фалов и директорий и на них, то файл robots.txt должен быть создан для каждого субдомена в отдельности и помещен в его корень.</p><h3>Способы запрета индексации для роботов. Удаление страниц из Гугла.</h3><p>Помимо запрета роботсом, есть и другие способы запретить индексацию для поисковых роботов. Например, поставить на странице мета-тег NOINDEX (не путать с чисто российским изобретением, просто тегом noindex внутри страницы!), или использовать соответствующие записи в файле .htaccess. Если неугодные страницы все же попали в индекс Гула, их можно оттуда удалить.</p><div align="center"><p><object width="425" height="355" classid="clsid:d27cdb6e-ae6d-11cf-96b8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0"><param name="src" value="http://www.youtube.com/v/nM2VDkXPt0I&rel=1"><param name="wmode" value="transparent"><embed width="425" height="355" type="application/x-shockwave-flash" src="http://www.youtube.com/v/nM2VDkXPt0I&rel=1" wmode="transparent"></object></p><p><em><strong>Запрет URL для робота и удаление страниц из Гугла</strong></em></p></div><p>В этом видео-фрагмента Матт Каттс объясняет, как лучше закрыть страницы от Гугла, и как их удалять, если они все же туда попали, несмотря на запрет в file роботс.</p><h2>Рекомендации Гугла по использованию файла РОБОТС.TXT</h2><p>Для конфиденциальных страниц лучше пользоваться более надежными методами, чем запрет их сканирования файлом роботс.txt. Одна из причин к этому — то, что поисковые роботы Интернета все равно могут показать ссылку на запрещенную страницу (правда, ничего не прописывая в сниппете), если на нее найдутся ссылки в Интернете. Кроме того, есть поисковые системы, которые вообще <strong>не признают файл robots.txt</strong> и Robot Exclusion Standard (стандарт по исключению роботов). Наконец, излишне любознательные посетители сайта могут захотеть взглянуть, что именно прячет веб-мастер от индексации. Для всех этих случаев помогает либо кодирования запретных страниц, либо установка паролей для их просмотра. При использовании файла ROBOTS.TXT Гугол не рекомендует:</p><ul><li>оставлять для сканирования адреса с результатами поиска по сайту</li><li>допускать к индексации большое число похожих по контенту страниц</li><li>позволять индексировать страницы, созданные как результат прокси</li></ul><p>Запреты робота в файле РОБОТС — очень полезный и нужным механизм для web-мастеров и оптимизаторов.</p><table><tbody><tr><td align="center"><p><img loading="lazy" title="Как пользоваться robots.txt?" src="https://4o1.ru/media/posts/44/file-robots-txt-zapret-robotov-files-robot-54.jpg" alt="Файл ROBOTS.TXT запрет роботов" width="300" height="260" border="0" sizes="(max-width: 48em) 100vw, 768px" srcset="https://4o1.ru/media/posts/44/responsive/file-robots-txt-zapret-robotov-files-robot-54-xs.jpg 300w, https://4o1.ru/media/posts/44/responsive/file-robots-txt-zapret-robotov-files-robot-54-sm.jpg 480w, https://4o1.ru/media/posts/44/responsive/file-robots-txt-zapret-robotov-files-robot-54-md.jpg 768w, https://4o1.ru/media/posts/44/responsive/file-robots-txt-zapret-robotov-files-robot-54-lg.jpg 1024w, https://4o1.ru/media/posts/44/responsive/file-robots-txt-zapret-robotov-files-robot-54-xl.jpg 1360w, https://4o1.ru/media/posts/44/responsive/file-robots-txt-zapret-robotov-files-robot-54-2xl.jpg 1600w"></p><p><em><strong>Файл ROBOTS.TXT запрет роботов</strong></em></p></td></tr></tbody></table></div><footer class="post__inner post__footer"><p class="post__last-updated">This article was updated on август 19, 2024</p><div class="post__share-tag-container"><div class="post__tag"><h3>Tagged in:</h3><ul><li><a href="https://4o1.ru/tags/it/">IT</a></li></ul></div><div class="post__share"><button class="post__share-button js-post__share-button icon" aria-label="Share button"><i class="fas fa-share-alt"></i></button><div class="post__share-popup js-post__share-popup"></div></div></div><div class="post__bio"><div><h3><a href="https://4o1.ru/authors/admin/" class="invert" rel="author">GUIDETO</a></h3></div></div></footer></article><div><strong>You should also read:</strong></div><div class="posts"><article><header><time datetime="2014-09-21T11:56" class="date">сентябрь 21, 2014</time><h2><a href="https://4o1.ru/sozdanie-faylov-fb2-dopolnenie-k-openofficeorg-writer-konvertor-exporttofb21-ooofbtools.html">Создание файлов FB2. Дополнение к OpenOffice.org Writer: Конвертор ExportToFB21+ OOoFBTools</a></h2></header><p></p><p>http://www.youtube.com/watch?v=OgAAknGpljo</p><p></p><ul class="actions special"><li><a href="https://4o1.ru/sozdanie-faylov-fb2-dopolnenie-k-openofficeorg-writer-konvertor-exporttofb21-ooofbtools.html" class="button">Full Story</a></li></ul></article><article><header><time datetime="2013-11-20T08:47" class="date">ноябрь 20, 2013</time><h2><a href="https://4o1.ru/prakticheskie-resheniya-po-ispolzovaniyu-fayla-htaccess.html">Практические решения по использованию файла .htaccess</a></h2></header><p><table width="95%" border="0" cellspacing="0" cellpadding="0" align="center"><tbody><tr><td><p align="left">Для чего служит .htaccess?</p></td></tr><tr><td><div align="justify"><p align="left">Набирая адрес в строке браузера, вы получаете на свой компьютер файлы, которые отображает браузер. Управление тем, какие файлы и как вам показывать (пересылать) осуществляет веб-сервер. Наиболее популярных серверов два: IIS и Apache.</p><p>Как и любая программа, веб-сервер имеет определенные настройки. Но, у вас, как пользователя Апача может (и скорее всего не будет, если говорить о виртуальном хостинге) прав менять конфигурацию Апача через его главные файлы, действие которых распространяется на всех пользователей этого сервера. Но, вы можете менять некоторые конфигурационные файлы, который распространяют свое действие только на ваш сайт. Один из таких файлов - .htaccess</p></div></td></tr></tbody></table></p><p align="left"></p><ul class="actions special"><li><a href="https://4o1.ru/prakticheskie-resheniya-po-ispolzovaniyu-fayla-htaccess.html" class="button">Full Story</a></li></ul></article><article><header><time datetime="2013-06-07T14:35" class="date">июнь 7, 2013</time><h2><a href="https://4o1.ru/prava-dostupa-na-fayly-i-papki-wordpress.html">Права доступа на файлы и папки WordPress</a></h2></header><p></p><p>Выставляем правильно доступ к файлам и папкам в файловой системе вашего блога</p><p>права 755 на папки</p><p>644 на файлы</p><p></p><ul class="actions special"><li><a href="https://4o1.ru/prava-dostupa-na-fayly-i-papki-wordpress.html" class="button">Full Story</a></li></ul></article><article><header><time datetime="2013-02-24T05:51" class="date">февраль 24, 2013</time><h2><a href="https://4o1.ru/pravilnyy-robotstxt-dlya-wordpress.html">Правильный robots.txt для WordPress</a></h2></header><p></p><p><img loading="lazy" title="robots" src="https://4o1.ru/media/posts/61/robots.png" alt="Файл robots.txt" width="128" height="128" sizes="(max-width: 48em) 100vw, 768px" srcset="https://4o1.ru/media/posts/61/responsive/robots-xs.png 300w, https://4o1.ru/media/posts/61/responsive/robots-sm.png 480w, https://4o1.ru/media/posts/61/responsive/robots-md.png 768w, https://4o1.ru/media/posts/61/responsive/robots-lg.png 1024w, https://4o1.ru/media/posts/61/responsive/robots-xl.png 1360w, https://4o1.ru/media/posts/61/responsive/robots-2xl.png 1600w"></p><p>Есть у движка wordpress одна проблема в техническом плане. Заключается она в дублирование контента и мусорных страниц. Эта штука сулит очень большие проблемы с поисковыми системами, особенно если очень увлекаться тегами (метками).</p><p>В самом плохом варианте сайт может попасть под фильтр Яндекса АГС (бан, когда в индексе остается 10 или менее страниц), и в дополнительный индекс Гугла. Объяснять, что такое АГС и дополнительный индекс я сейчас не буду, эта тема отдельного разговора, а вот как решить проблему с дублями я расскажу.</p><p></p><ul class="actions special"><li><a href="https://4o1.ru/pravilnyy-robotstxt-dlya-wordpress.html" class="button">Full Story</a></li></ul></article></div></main><footer id="copyright"><ul><li>&copy; Massively</li><li>Design: <a href="https://html5up.net" target="_blank" rel="nofollow noopener">HTML5 UP</a></li><li>Powered by Publii</li></ul></footer></div><script src="https://4o1.ru/assets/js/jquery.min.js?v=c9771cc3e90e18f5336eedbd0fffb2cf"></script><script src="https://4o1.ru/assets/js/jquery.scrollex.min.js?v=f89065e3d988006af9791b44561d7c90"></script><script src="https://4o1.ru/assets/js/jquery.scrolly.min.js?v=1ed5a78bde1476875a40f6b9ff44fc14"></script><script src="https://4o1.ru/assets/js/browser.min.js?v=c07298dd19048a8a69ad97e754dfe8d0"></script><script src="https://4o1.ru/assets/js/breakpoints.min.js?v=81a479eb099e3b187613943b085923b8"></script><script src="https://4o1.ru/assets/js/util.min.js?v=4201a626f8c9b614a663b3a1d7d82615"></script><script src="https://4o1.ru/assets/js/main.min.js?v=56233c354bd814758be8bff42f7e13a5"></script><script>/*<![CDATA[*/var images=document.querySelectorAll("img[loading]");for(var i=0;i<images.length;i++){if(images[i].complete){images[i].classList.add("is-loaded")}else{images[i].addEventListener("load",function(){this.classList.add("is-loaded")},false)}};/*]]>*/</script></body></html>